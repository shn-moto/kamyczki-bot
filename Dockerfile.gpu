# Dockerfile for local development with NVIDIA GPU (GTX 1070, etc.)
# Requires: nvidia-container-toolkit

FROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04

WORKDIR /app

# Install Python 3.11 and system dependencies
RUN apt-get update && apt-get install -y --no-install-recommends \
    software-properties-common \
    curl \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update \
    && apt-get install -y --no-install-recommends \
    python3.11 \
    python3.11-venv \
    python3.11-dev \
    libgl1 \
    libglib2.0-0 \
    && rm -rf /var/lib/apt/lists/* \
    && ln -sf /usr/bin/python3.11 /usr/bin/python \
    && curl -sS https://bootstrap.pypa.io/get-pip.py | python3.11

# Install PyTorch with CUDA 11.8 support
RUN python -m pip install --no-cache-dir \
    torch torchvision \
    --index-url https://download.pytorch.org/whl/cu118

# Install other dependencies
COPY requirements-gpu.txt .
RUN python -m pip install --no-cache-dir -r requirements-gpu.txt

# Pre-download models during build
RUN python -c "import open_clip; open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')"
RUN python -c "from rembg import new_session; new_session('u2net')"

# Copy application code and wait script
COPY src/ ./src/
COPY wait-for-tunnel.sh .
RUN chmod +x wait-for-tunnel.sh

ENV PORT=8080
ENV USE_LOCAL_ML=true
ENV NVIDIA_VISIBLE_DEVICES=all

# Use wait-for-tunnel script as entrypoint (same as CPU version)
ENTRYPOINT ["/bin/sh", "./wait-for-tunnel.sh"]
